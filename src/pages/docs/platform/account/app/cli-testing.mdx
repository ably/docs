---
title: CLI testing
meta_description: "Use the Ably CLI for comprehensive testing of your application's real-time functionality from the command line, including automated testing scenarios."
meta_keywords: "Ably CLI testing, command line testing, automated testing, real-time testing, CLI tools"
redirect_from:
  - /docs/account/app/cli
---

Use the Ably CLI for comprehensive testing of your application's real-time functionality from the command line, enabling automated testing scenarios and development workflows.

The CLI testing tools complement the dashboard's dev console by providing scriptable, automated testing capabilities that integrate with your development and CI/CD processes.

## Accessing CLI testing

To use CLI testing for your application:

1. Install and configure the Ably CLI
2. Authenticate with your Ably account
3. Select your application for testing
4. Run testing commands and scenarios

## Setting up CLI testing

### Installation and authentication

Install the Ably CLI and authenticate:

<Code>
```shell
# Install Ably CLI globally
npm install -g @ably/cli

# Login and authenticate
ably login

# List your apps
ably apps list

# Switch to your app
ably apps switch <app-id>
```
</Code>

### Configuration verification

Verify your setup before testing:

<Code>
```shell
# Check current app and API key
ably status

# Test basic connectivity
ably channels list
```
</Code>

## Testing methodologies

### Interactive testing

Test functionality interactively from the command line:

#### Message testing

Test message publishing and subscription:

<Code>
```shell
# Subscribe to a channel (run in one terminal)
ably channels subscribe test-channel

# Publish messages (run in another terminal)
ably channels publish test-channel "Hello World"

# Publish multiple messages
ably channels publish --count 5 test-channel "Message {{.Count}}"

# Publish with event name
ably channels publish test-channel --name "user-joined" "User data"
```
</Code>

#### Presence testing

Test presence functionality:

<Code>
```shell
# Enter presence
ably channels presence enter test-channel --client-id user1 --data '{"status": "online"}'

# Subscribe to presence events
ably channels presence subscribe test-channel

# Update presence data
ably channels presence update test-channel --data '{"status": "away"}'

# Leave presence
ably channels presence leave test-channel
```
</Code>

### Automated testing scenarios

Create automated test scripts for common scenarios:

#### Connection reliability testing

Test connection stability and recovery:

<Code>
```shell
#!/bin/bash
# Test connection recovery

echo "Testing connection reliability..."

# Subscribe to channel in background
ably channels subscribe reliability-test &
SUBSCRIBE_PID=$!

# Publish messages at intervals
for i in {1..10}; do
    ably channels publish reliability-test "Test message $i"
    sleep 2
done

# Clean up
kill $SUBSCRIBE_PID
echo "Connection test complete"
```
</Code>

#### Load testing

Test performance under load:

<Code>
```shell
#!/bin/bash
# Simple load testing script

CHANNEL="load-test-channel"
MESSAGE_COUNT=100
CONCURRENT_PUBLISHERS=5

echo "Starting load test: $MESSAGE_COUNT messages with $CONCURRENT_PUBLISHERS publishers"

# Function to publish messages
publish_messages() {
    local publisher_id=$1
    for i in $(seq 1 $((MESSAGE_COUNT / CONCURRENT_PUBLISHERS))); do
        ably channels publish $CHANNEL "Publisher $publisher_id - Message $i"
    done
}

# Start concurrent publishers
for i in $(seq 1 $CONCURRENT_PUBLISHERS); do
    publish_messages $i &
done

# Wait for all publishers to complete
wait
echo "Load test complete"
```
</Code>

#### Integration testing

Test integration points:

<Code>
```shell
#!/bin/bash
# Integration testing script

APP_NAME="my-app"
TEST_CHANNEL="integration-test"

echo "Starting integration tests for $APP_NAME"

# Test 1: Basic connectivity
echo "Test 1: Basic connectivity"
if ably channels list > /dev/null 2>&1; then
    echo "‚úì Connectivity test passed"
else
    echo "‚úó Connectivity test failed"
    exit 1
fi

# Test 2: Message publishing
echo "Test 2: Message publishing"
if ably channels publish $TEST_CHANNEL "Integration test message" > /dev/null 2>&1; then
    echo "‚úì Message publishing test passed"
else
    echo "‚úó Message publishing test failed"
    exit 1
fi

# Test 3: Channel history
echo "Test 3: Channel history"
if ably channels history $TEST_CHANNEL --limit 1 > /dev/null 2>&1; then
    echo "‚úì Channel history test passed"
else
    echo "‚úó Channel history test failed"
    exit 1
fi

echo "All integration tests passed"
```
</Code>

## Advanced testing features

### Chat testing

Test chat functionality using CLI:

<Code>
```shell
# List chat rooms
ably chat rooms list

# Send chat messages
ably chat messages send room-1 "Hello chat!"

# Subscribe to chat messages
ably chat messages subscribe room-1

# Test typing indicators
ably chat typing start room-1 --client-id user1
ably chat typing stop room-1 --client-id user1

# Test message reactions
ably chat reactions send room-1 message-id --reaction "üëç"
```
</Code>

### Spaces testing

Test collaborative spaces:

<Code>
```shell
# List spaces
ably spaces list

# Enter a space
ably spaces members enter workspace-1 --client-id user1

# Set member location
ably spaces locations set workspace-1 --x 100 --y 200

# Set cursor position
ably spaces cursors set workspace-1 --x 150 --y 175

# Acquire a lock
ably spaces locks acquire workspace-1 --lock-id "document-1"
```
</Code>

### Statistics and monitoring

Monitor application performance via CLI:

<Code>
```shell
# Get app statistics
ably apps stats --start-time "2024-01-01" --end-time "2024-01-02"

# Monitor live statistics
ably apps stats --live

# Check account usage
ably accounts stats

# Monitor logs in real-time
ably logs subscribe
```
</Code>

## Testing best practices

### Test organization

Structure your CLI tests effectively:

| Practice | Description |
| -------- | ----------- |
| Script organization | Create dedicated test scripts for different scenarios |
| Environment separation | Use different apps for development, testing, and production |
| Test isolation | Ensure tests don't interfere with each other |
| Cleanup procedures | Remove test data after test completion |

### Automated testing integration

Integrate CLI testing into your development workflow:

#### CI/CD integration

Add CLI tests to your CI/CD pipeline:

<Code>
```yaml
# GitHub Actions example
name: Ably CLI Tests
on: [push, pull_request]

jobs:
  cli-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Install Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          
      - name: Install Ably CLI
        run: npm install -g @ably/cli
        
      - name: Authenticate with Ably
        run: ably auth --token ${{ secrets.ABLY_CLI_TOKEN }}
        
      - name: Run CLI integration tests
        run: ./scripts/run-cli-tests.sh
```
</Code>

#### Local development testing

Create development testing scripts:

<Code>
```shell
#!/bin/bash
# dev-test.sh - Development testing script

set -e

echo "Running development tests..."

# Switch to development app
ably apps switch dev-app-id

# Run quick smoke tests
./tests/smoke-tests.sh

# Run feature tests
./tests/feature-tests.sh

echo "Development tests completed successfully"
```
</Code>

### Performance testing

Use CLI for performance analysis:

#### Latency testing

Measure message delivery latency:

<Code>
```shell
#!/bin/bash
# Latency testing script

CHANNEL="latency-test"
ITERATIONS=10

echo "Testing message latency..."

for i in $(seq 1 $ITERATIONS); do
    START_TIME=$(date +%s%N)
    ably channels publish $CHANNEL "Latency test $i" --wait
    END_TIME=$(date +%s%N)
    
    LATENCY=$((($END_TIME - $START_TIME) / 1000000))
    echo "Message $i latency: ${LATENCY}ms"
done
```
</Code>

#### Throughput testing

Test message throughput capabilities:

<Code>
```shell
#!/bin/bash
# Throughput testing

CHANNEL="throughput-test"
DURATION=60  # seconds
MESSAGE_SIZE=1024  # bytes

echo "Starting throughput test for ${DURATION} seconds..."

# Generate test message of specified size
TEST_MESSAGE=$(printf '%*s' $MESSAGE_SIZE | tr ' ' 'A')

START_TIME=$(date +%s)
MESSAGE_COUNT=0

while [ $(($(date +%s) - START_TIME)) -lt $DURATION ]; do
    ably channels publish $CHANNEL "$TEST_MESSAGE" > /dev/null 2>&1
    MESSAGE_COUNT=$((MESSAGE_COUNT + 1))
done

THROUGHPUT=$((MESSAGE_COUNT / DURATION))
echo "Throughput: $THROUGHPUT messages/second"
```
</Code>

## Debugging with CLI

### Connection debugging

Debug connection issues using CLI tools:

<Code>
```shell
# Check connection status
ably status

# Test connectivity with different environments
ably channels list --environment sandbox
ably channels list --environment production

# Debug authentication issues
ably auth status
ably auth refresh
```
</Code>

### Message debugging

Debug message delivery problems:

<Code>
```shell
# Check channel activity
ably channels list --active

# Monitor message flow
ably channels subscribe debug-channel --verbose

# Check message history
ably channels history debug-channel --limit 50

# Test with different message formats
ably channels publish debug-channel '{"type": "test", "data": "value"}'
```
</Code>

### Error handling testing

Test error conditions and recovery:

<Code>
```shell
#!/bin/bash
# Error handling test script

echo "Testing error handling scenarios..."

# Test invalid channel names
ably channels subscribe "invalid channel name" 2>&1 | grep -q "error" && echo "‚úì Invalid channel name handled"

# Test unauthorized access
ORIGINAL_KEY=$(ably status | grep "API Key" | cut -d: -f2 | xargs)
ably auth set --api-key invalid-key
ably channels list 2>&1 | grep -q "unauthorized" && echo "‚úì Unauthorized access handled"

# Restore original key
ably auth set --api-key "$ORIGINAL_KEY"

echo "Error handling tests complete"
```
</Code>

## CLI testing vs dashboard testing

### When to use CLI testing

CLI testing is ideal for:

| Scenario | Advantage |
| -------- | --------- |
| Automated testing | Scriptable and repeatable test execution |
| CI/CD integration | Easy integration with build pipelines |
| Load testing | Generate high volumes of test traffic |
| Performance testing | Precise timing and measurement capabilities |
| Regression testing | Automated verification of functionality |

### When to use dashboard testing

Dashboard dev console is better for:

| Scenario | Advantage |
| -------- | --------- |
| Visual debugging | Real-time visual feedback and monitoring |
| Interactive exploration | Point-and-click interface for ad-hoc testing |
| Quick prototyping | Rapid testing of ideas without scripting |
| Team collaboration | Shared visual interface for team members |
| Real-time monitoring | Live dashboard view of application activity |

### Combined approach

Use both CLI and dashboard testing together:

1. Use dashboard for initial development and debugging
2. Create CLI scripts for repetitive test scenarios
3. Integrate CLI tests into automated testing pipelines
4. Use dashboard to investigate issues found by CLI tests

## Troubleshooting CLI testing

### Common issues and solutions

| Issue | Cause | Solution |
| ----- | ----- | -------- |
| Authentication failures | Expired or invalid tokens | Run `ably login` to re-authenticate |
| Connection timeouts | Network or service issues | Check network connectivity and service status |
| Permission errors | Insufficient API key capabilities | Verify API key permissions in dashboard |
| Script failures | Environment or dependency issues | Validate CLI installation and environment setup |

### Diagnostic commands

Use these commands for troubleshooting:

<Code>
```shell
# Check CLI version and status
ably version
ably status

# Test basic connectivity
ably ping

# Validate authentication
ably auth validate

# Check app configuration
ably apps show

# Test API key capabilities
ably api-keys show
```
</Code>

CLI testing provides powerful automation capabilities that complement the dashboard's interactive tools, enabling comprehensive testing strategies for your Ably applications.