---
title: Kafka rule
meta_description: "Ably allows you to send data to Kafka based on message, channel lifecycle, channel occupancy, and presence events."
meta_keywords: "Kafka, integrations, events, serverless"
languages:
  - none
redirect_from:
  - /docs/general/firehose/kafka-rule
---

Use Ably's "Firehose":/docs/integrations/streaming Kafka rule to send "data":/docs/integrations/streaming#data-sources such as messages, occupancy, lifecycle and presence events from Ably to Kafka.

If you want to send data from Kafka to Ably, you can use the "Ably Kafka Connector":/docs/general/kafka-connector, rather than Kafka rules.

h2(#creating-kafka-rule). Creating a Kafka rule

There are two ways to create a Kafka rule:

* Using the "Ably Dashboard":https://ably.com/dashboard.
* Using the "Control API":/docs/account/control-api.

h3(#creating-rule-dashboard). Creating a Kafka rule in the dashboard

To create a rule in your "dashboard":https://ably.com/dashboard#58:

* Login and select the application you wish to integrate with Kafka.
* Click the *Integrations* tab.
* Click the *New Integration Rule* button.
* Choose Firehose.
* Choose Kafka.
* Configure the settings applicable to your use case and your Kafka installation.
* Click *Create* to create the rule.

h4(#settings). Kafka rule settings

The following explains the Kafka general rule settings:

|_. Section                                                        |_. Purpose                                                                               |
|"Source":/docs/integrations/streaming#data-sources |Select the type of event source.                                                         |
|Channel filter                                                    |Allows filtering of the rule based on a regular expression matching the channel name.    |
|Routing key                                                       |Used to route messages to Kafka topics.                                                  |
|Mechanism                                                         |Dropdown to select the SASL/SCRAM mechanism used for Kafka connection.                   |
|Brokers                                                           |List of Kafka broker endpoints in the format `<host>:<port>`.                            |
|Another broker                                                    |Option to add additional Kafka broker endpoints.                                         |


In this section you need to set up your Authentication for Kafka by selecting your preferred mechanism for authentication and providing credentials.

The supported Authentication Mechanisms are:

* "SASL/PLAIN":https://docs.confluent.io/platform/current/kafka/authentication_sasl/authentication_sasl_plain.html#kafka-sasl-auth-plain
* "SASL/SCRAM-SHA-256":https://docs.confluent.io/platform/current/kafka/authentication_sasl/authentication_sasl_scram.html#kafka-sasl-auth-scram
* "SASL/SCRAM-SHA-512":https://docs.confluent.io/platform/current/kafka/authentication_sasl/authentication_sasl_scram.html

* Click *Create* to create the rule.

h3(#creating-rule-control-api). Creating a Kafka rule using Control API

See some examples of creating rules in the "rules section":/docs/account/control-api#examples-rules of the Control API documentation. You can also refer to the "rule section":/docs/api/control-api#tag/rules/paths/~1apps~1{app_id}~1rules/post of the Control API Reference for information on creating a Kafka rule. You will need to select a @ruleType@ of @kafka@.
